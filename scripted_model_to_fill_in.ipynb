{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@font-face {\n",
    "  font-family: CharisSILW;\n",
    "  src: url(files/CharisSIL-R.woff);\n",
    "}\n",
    "@font-face {\n",
    "  font-family: CharisSILW;\n",
    "  font-style: italic;\n",
    "  src: url(files/CharisSIL-I.woff);\n",
    "}\n",
    "@font-face {\n",
    "\tfont-family: CharisSILW;\n",
    "\tfont-weight: bold;\n",
    "\tsrc: url(files/CharisSIL-B.woff);\n",
    "}\n",
    "@font-face {\n",
    "\tfont-family: CharisSILW;\n",
    "\tfont-weight: bold;\n",
    "\tfont-style: italic;\n",
    "\tsrc: url(files/CharisSIL-BI.woff);\n",
    "}\n",
    "\n",
    "div.cell, div.text_cell_render{\n",
    "    max-width:1000px;\n",
    "}\n",
    "\n",
    "h1 {\n",
    "    text-align:center;\n",
    "    font-family: Charis SIL, CharisSILW, serif;\n",
    "}\n",
    "\n",
    ".rendered_html {\n",
    "    font-size: 130%;\n",
    "    line-height: 1.3;\n",
    "}\n",
    "\n",
    ".rendered_html li {\n",
    "    line-height: 2;\n",
    "}\n",
    "\n",
    ".rendered_html h1{\n",
    "    line-height: 1.3;\n",
    "}\n",
    "\n",
    ".rendered_html h2{\n",
    "    line-height: 1.2;\n",
    "}\n",
    "\n",
    ".rendered_html h3{\n",
    "    line-height: 1.0;\n",
    "}\n",
    "\n",
    ".text_cell_render {\n",
    "    font-family: Charis SIL, CharisSILW, serif;\n",
    "    line-height: 145%;\n",
    "}\n",
    "\n",
    "li li {\n",
    "    font-size: 85%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Data Science in Python\n",
    "\n",
    "<img src=\"scikit-learn.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is the workbook for the \"End-to-End Data Analysis in Python\" workshop\n",
    "at the Open Data Science Conference 2017, in beautiful San Francisco. The objective is to complete the \"Pump it Up: Mining the Water Table\" challenge\n",
    "on [drivendata.org](www.drivendata.org/competitions/7/); the objective here is to predict\n",
    "African wells that are non-functional or in need of repair.  Per the rules of the\n",
    "competition, you should register for an account with drivendata.org, at which point you\n",
    "can download the training set values and labels.  We will be working with those datasets\n",
    "during this workshop.  You should download those files to the directory in which this\n",
    "notebook lives, and name them wells_features.csv and wells_labels.csv (to be consistent\n",
    "with our nomenclature).  You are also encouraged to continue developing your solution\n",
    "after this workshop, and/or to enter your solution in the competition on the drivendata\n",
    "website!\n",
    " \n",
    " ### Code requirements\n",
    " Here's the environment you'll need to work with this code base:\n",
    "\n",
    " * python 3 (2.x may work with minor changes, but no guarantees)\n",
    " * pandas\n",
    " * scikit-learn\n",
    " * numpy\n",
    "\n",
    "# First Draft of an Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69572</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34310</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67743</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19728</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19816</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54551</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53934</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46144</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49056</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50409</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36957</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50495</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53752</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61848</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48451</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58155</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34169</th>\n",
       "      <td>functional needs repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18274</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  status_group\n",
       "id                            \n",
       "69572               functional\n",
       "8776                functional\n",
       "34310               functional\n",
       "67743           non functional\n",
       "19728               functional\n",
       "9944                functional\n",
       "19816           non functional\n",
       "54551           non functional\n",
       "53934           non functional\n",
       "46144               functional\n",
       "49056               functional\n",
       "50409               functional\n",
       "36957               functional\n",
       "50495               functional\n",
       "53752               functional\n",
       "61848               functional\n",
       "48451           non functional\n",
       "58155           non functional\n",
       "34169  functional needs repair\n",
       "18274               functional"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "  \n",
    "features_df = pd.DataFrame.from_csv(\"well_data.csv\")\n",
    "labels_df   = pd.DataFrame.from_csv(\"well_labels.csv\")  \n",
    "labels_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice feature of ipython notebooks is it's easy to make small changes to code and\n",
    "then re-execute quickly, to see how things change.  For example, printing the first 5 lines\n",
    "of the labels dataframe (which is the default) isn't really ideal here, since there's a label\n",
    "(\"functional needs repair\") which doesn't appear in the first five lines.  Type 20 in the\n",
    "parentheses labels_df.head(), so it now reads labels_df.head(20), and press shift-enter to\n",
    "rerun the code.  See the difference?\n",
    " \n",
    "Now take a quick look at the features, again by calling .head().  You can print or as few\n",
    "rows as you like.  Take a quick look at the data--approximately how many features are there?\n",
    "Are they all numeric, or will you have to do work to transform non-numeric features into\n",
    "numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69572</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>3/14/11</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>...</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3/6/13</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34310</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2/25/13</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>...</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67743</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1/28/13</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>0</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7/13/11</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "id                                                                        \n",
       "69572      6000.0       3/14/11         Roman        1390         Roman   \n",
       "8776          0.0        3/6/13       Grumeti        1399       GRUMETI   \n",
       "34310        25.0       2/25/13  Lottery Club         686  World vision   \n",
       "67743         0.0       1/28/13        Unicef         263        UNICEF   \n",
       "19728         0.0       7/13/11   Action In A           0       Artisan   \n",
       "\n",
       "       longitude   latitude              wpt_name  num_private  \\\n",
       "id                                                               \n",
       "69572  34.938093  -9.856322                  none            0   \n",
       "8776   34.698766  -2.147466              Zahanati            0   \n",
       "34310  37.460664  -3.821329           Kwa Mahundi            0   \n",
       "67743  38.486161 -11.155298  Zahanati Ya Nanyumbu            0   \n",
       "19728  31.130847  -1.825359               Shuleni            0   \n",
       "\n",
       "                         basin          ...          payment_type  \\\n",
       "id                                      ...                         \n",
       "69572               Lake Nyasa          ...              annually   \n",
       "8776             Lake Victoria          ...             never pay   \n",
       "34310                  Pangani          ...            per bucket   \n",
       "67743  Ruvuma / Southern Coast          ...             never pay   \n",
       "19728            Lake Victoria          ...             never pay   \n",
       "\n",
       "      water_quality  quality_group      quantity quantity_group  \\\n",
       "id                                                                \n",
       "69572          soft           good        enough         enough   \n",
       "8776           soft           good  insufficient   insufficient   \n",
       "34310          soft           good        enough         enough   \n",
       "67743          soft           good           dry            dry   \n",
       "19728          soft           good      seasonal       seasonal   \n",
       "\n",
       "                     source           source_type source_class  \\\n",
       "id                                                               \n",
       "69572                spring                spring  groundwater   \n",
       "8776   rainwater harvesting  rainwater harvesting      surface   \n",
       "34310                   dam                   dam      surface   \n",
       "67743           machine dbh              borehole  groundwater   \n",
       "19728  rainwater harvesting  rainwater harvesting      surface   \n",
       "\n",
       "                   waterpoint_type waterpoint_type_group  \n",
       "id                                                        \n",
       "69572           communal standpipe    communal standpipe  \n",
       "8776            communal standpipe    communal standpipe  \n",
       "34310  communal standpipe multiple    communal standpipe  \n",
       "67743  communal standpipe multiple    communal standpipe  \n",
       "19728           communal standpipe    communal standpipe  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming string labels into integers\n",
    "The machine learning algorithms downstream are not going to handle it well if the class labels\n",
    "used for training are strings; instead, we'll want to use integers.  The mapping that we'll use is that \"non functional\" will be transformed to 0, \"functional needs repair\" will be 1, and \"functional\" becomes 2.\n",
    " \n",
    "There are a number of ways to do this; the framework below uses `applymap()` in pandas.\n",
    " [Here's](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.applymap.html) the documentation for applymap(); in the code below, I've filled in the function body for `label_map(y)` so that if y is \"functional\", label_map returns 2; if y is \"functional needs repair\" then it should return 1, and \"non functional\" is 0. There's a print statement there to help you confirm that the label transformation is working\n",
    " properly.\n",
    " \n",
    " As an aside, you could also use `apply()` here if you like.  The difference between `apply()`\n",
    " and `applymap()` is that `applymap()` operates on a whole dataframe while `apply()` operates on a series\n",
    " (or you can think of it as operating on one column of your dataframe).  Since `labels_df` only has\n",
    " one column (aside from the index column), either one will work here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69572</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34310</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67743</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19728</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       status_group\n",
       "id                 \n",
       "69572             2\n",
       "8776              2\n",
       "34310             2\n",
       "67743             0\n",
       "19728             2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_map(y):\n",
    "    if y==\"functional\":\n",
    "        return 2\n",
    "    elif y==\"functional needs repair\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "labels_df = labels_df.applymap(label_map)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming string features into integers\n",
    " \n",
    "Now that the labels are ready, we'll turn our attention to the features.  Many of the features\n",
    "are categorical, where a feature can take on one of a few discrete values, which are not ordered.\n",
    "I've written a function, `transform_feature(df, column)`, below so that it takes our `features_df` and\n",
    "the name of a column in that dataframe, and returns the same dataframe but with the indicated\n",
    "feature encoded with integers rather than strings.\n",
    "\n",
    "We've provided code to wrap your transformer function in a loop iterating through all the columns that should\n",
    "be transformed.\n",
    "\n",
    "Last, there's a line of code at the bottom of the block below that removes the `date_recorded` column from `features_df`.  Time-series information like dates and times need special treatment, which we won't be going into today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69572</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>392</td>\n",
       "      <td>1390</td>\n",
       "      <td>450</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>21093</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4394</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>555</td>\n",
       "      <td>1399</td>\n",
       "      <td>1043</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>30451</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12088</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34310</th>\n",
       "      <td>25.0</td>\n",
       "      <td>342</td>\n",
       "      <td>686</td>\n",
       "      <td>348</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>9932</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3523</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67743</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1122</td>\n",
       "      <td>263</td>\n",
       "      <td>246</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>2029</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8426</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>1193</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>29205</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10975</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1303</td>\n",
       "      <td>0</td>\n",
       "      <td>852</td>\n",
       "      <td>39.172796</td>\n",
       "      <td>-4.765587</td>\n",
       "      <td>12650</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9726</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19816</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>1595</td>\n",
       "      <td>33.362410</td>\n",
       "      <td>-3.766365</td>\n",
       "      <td>23229</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2367</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54551</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1435</td>\n",
       "      <td>0</td>\n",
       "      <td>852</td>\n",
       "      <td>32.620617</td>\n",
       "      <td>-4.226198</td>\n",
       "      <td>1659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1598</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53934</th>\n",
       "      <td>0.0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "      <td>32.711100</td>\n",
       "      <td>-5.146712</td>\n",
       "      <td>26994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12223</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1193</td>\n",
       "      <td>30.626991</td>\n",
       "      <td>-1.257051</td>\n",
       "      <td>29279</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15419</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount_tsh  funder  gps_height  installer  longitude   latitude  \\\n",
       "id                                                                       \n",
       "69572      6000.0     392        1390        450  34.938093  -9.856322   \n",
       "8776          0.0     555        1399       1043  34.698766  -2.147466   \n",
       "34310        25.0     342         686        348  37.460664  -3.821329   \n",
       "67743         0.0    1122         263        246  38.486161 -11.155298   \n",
       "19728         0.0    1200           0       1193  31.130847  -1.825359   \n",
       "9944         20.0    1303           0        852  39.172796  -4.765587   \n",
       "19816         0.0    1820           0       1595  33.362410  -3.766365   \n",
       "54551         0.0    1435           0        852  32.620617  -4.226198   \n",
       "53934         0.0     161           0        418  32.711100  -5.146712   \n",
       "46144         0.0      49           0       1193  30.626991  -1.257051   \n",
       "\n",
       "       wpt_name  num_private  basin  subvillage          ...            \\\n",
       "id                                                       ...             \n",
       "69572     21093            0      7        4394          ...             \n",
       "8776      30451            0      1       12088          ...             \n",
       "34310      9932            0      2        3523          ...             \n",
       "67743      2029            0      3        8426          ...             \n",
       "19728     29205            0      1       10975          ...             \n",
       "9944      12650            0      2        9726          ...             \n",
       "19816     23229            0      6        2367          ...             \n",
       "54551      1659            0      0        1598          ...             \n",
       "53934     26994            0      0       12223          ...             \n",
       "46144     29279            0      1       15419          ...             \n",
       "\n",
       "       payment_type  water_quality  quality_group  quantity  quantity_group  \\\n",
       "id                                                                            \n",
       "69572             0              4              1         3               3   \n",
       "8776              2              4              1         2               2   \n",
       "34310             5              4              1         3               3   \n",
       "67743             2              4              1         0               0   \n",
       "19728             2              4              1         1               1   \n",
       "9944              5              2              2         3               3   \n",
       "19816             2              4              1         3               3   \n",
       "54551             6              1              0         3               3   \n",
       "53934             2              2              2         1               1   \n",
       "46144             2              4              1         3               3   \n",
       "\n",
       "       source  source_type  source_class  waterpoint_type  \\\n",
       "id                                                          \n",
       "69572       9            6             0                5   \n",
       "8776        3            2             1                5   \n",
       "34310       0            0             1                4   \n",
       "67743       5            3             0                4   \n",
       "19728       3            2             1                5   \n",
       "9944        8            5             2                4   \n",
       "19816       5            3             0                2   \n",
       "54551       6            4             0                2   \n",
       "53934       5            3             0                2   \n",
       "46144       6            4             0                2   \n",
       "\n",
       "       waterpoint_type_group  \n",
       "id                            \n",
       "69572                      4  \n",
       "8776                       4  \n",
       "34310                      4  \n",
       "67743                      4  \n",
       "19728                      4  \n",
       "9944                       4  \n",
       "19816                      2  \n",
       "54551                      2  \n",
       "53934                      2  \n",
       "46144                      2  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_feature(df, column_name):\n",
    "    # sets don't allow repeated values--casting a list\n",
    "    # to a set will get rid of all duplicates\n",
    "    # NB: sets are not generally ordered in python\n",
    "    unique_values = set(df[column_name].tolist())\n",
    "    transformer_dict = {}\n",
    "    for ii, value in enumerate(unique_values):\n",
    "        transformer_dict[value] = ii\n",
    "        \n",
    "    # create a mapping from strings to integers\n",
    "    def label_map(y):\n",
    "        return transformer_dict[y]\n",
    "    \n",
    "    df[column_name] = df[column_name].apply(label_map)\n",
    "    return df\n",
    "\n",
    "### list of column names indicating which columns to transform; \n",
    "### this is just a start!  Use some of the print(labels_df.head())\n",
    "### output upstream to help you decide which columns get the\n",
    "### transformation\n",
    "columns_to_transform = [\"funder\", \"installer\", \"wpt_name\", \"basin\", \"subvillage\",\n",
    "                    \"region\", \"lga\", \"ward\", \"public_meeting\", \"recorded_by\",\n",
    "                    \"scheme_management\", \"scheme_name\", \"permit\",\n",
    "                    \"extraction_type\", \"extraction_type_group\",\n",
    "                    \"extraction_type_class\",\n",
    "                    \"management\", \"management_group\",\n",
    "                    \"payment\", \"payment_type\",\n",
    "                    \"water_quality\", \"quality_group\", \"quantity\", \"quantity_group\",\n",
    "                    \"source\", \"source_type\", \"source_class\",\n",
    "                    \"waterpoint_type\", \"waterpoint_type_group\"]\n",
    "for column in columns_to_transform:\n",
    "    features_df = transform_feature(features_df, column)\n",
    "    \n",
    "### remove the \"date_recorded\" column--we're not going to make use\n",
    "### of time-series data today\n",
    "if \"date_recorded\" in features_df.columns.values:\n",
    "    features_df.drop(\"date_recorded\", axis=1, inplace=True)\n",
    "    \n",
    "features_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, a couple last steps to get everything ready for sklearn.  The features and labels are taken out of their dataframes and put into a numpy.ndarray and list, respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = features_df.as_matrix()\n",
    "y = labels_df[\"status_group\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting well failures with logistic regression\n",
    "\n",
    "The cheapest and easiest way to train on one portion of your dataset and test on another, and to get a measure of model quality at the same time, is to use ``sklearn.cross_validation.cross_val_score()``.  This splits your data into 3 equal portions, trains on two of them, and tests on the third.  This process repeats 3 times.  That's why 3 numbers get printed in the code block below.\n",
    "\n",
    "You don't have to add anything to the code block, it's ready to go already.  However, use it for reference in the next part of the tutorial, where you will be looking at other sklearn algorithms.\n",
    "\n",
    "Heads up: it can be a little slow.  This took a minute or two to evaluate on my MacBook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67267677  0.67843434  0.67772727]\n"
     ]
    }
   ],
   "source": [
    "### you fill this in!\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "clf= sklearn.linear_model.LogisticRegression()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing logistic regression to tree-based methods\n",
    "\n",
    "We have a baseline logistic regression model for well failures.  Let's compare to a couple of other classifiers, a decision tree classifier and a random forest classifier, to see which one seems to do the best.  \n",
    "\n",
    "Code this up on your own.  You can use the code in the box above as a kind of template, and just drop in the new classifiers.  The sklearn documentation might also be helpful:\n",
    "* [Decision tree classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "* [Random forest classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "We will talk about all three of these models more in the next part of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7379798   0.73525253  0.74383838]\n",
      "[ 0.79075758  0.79116162  0.78671717]\n"
     ]
    }
   ],
   "source": [
    "### you fill this in!\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score(clf, X, y)\n",
    "print(score)\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score(clf, X, y)\n",
    "print(score)\n",
    "\n",
    "# Higher scores mean better model.  Scale 0 - 1\n",
    "# Random forest is often the best and not as slow - speaker rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations!  You have a working data science setup, in which you have:\n",
    "* read in data\n",
    "* transformed features and labels to make the data amenable to machine learning\n",
    "* made a train/test split (this was done implicitly when you called ``cross_val_score``)\n",
    "* evaluated several models for identifying wells that are failed or in danger of failing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paying down technical debt and tuning the models\n",
    "\n",
    "We got things running really fast, which is great, but at the cost of being a little quick-and-dirty about some details.  First, we got the features encoded as integers, but they really should be dummy variables.  Second, it's worth going through the models a little more thoughtfully, to try to understand their performance and if there's any more juice we can get out of them.\n",
    "\n",
    "### One-hot encoding to make dummy variables\n",
    "A problem with representing categorical variables as integers is that integers are ordered, while categories are not.  The standard way to deal with this is to use dummy variables; one-hot encoding is a very common way of dummying.  Each possible category becomes a new boolean feature.  For example, if our dataframe looked like this: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``index      country\n",
    "1          \"United States\"\n",
    "2          \"Mexico\"\n",
    "3          \"Mexico\"\n",
    "4          \"Canada\"\n",
    "5          \"United States\"\n",
    "6          \"Canada\"``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then after dummying it will look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``index      country_UnitedStates     country_Mexico    country_Canada\n",
    "1          1                        0                 0\n",
    "2          0                        1                 0\n",
    "3          0                        1                 0\n",
    "4          0                        0                 1\n",
    "5          1                        0                 0\n",
    "6          0                        0                 1``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully the origin of the name is clear--each variable is now encoded over several boolean columns, one of which is true (hot) and the others are false.\n",
    "\n",
    "Now we'll write a hot-encoder function that takes the data frame and the title of a column, and returns the same data frame but one-hot encoding performed on the indicated feature.\n",
    "\n",
    "<font color=\"red\">Protip</font>: sklearn has a [one-hot encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) function available that will be your friend here.\n",
    "\n",
    "<font color=\"red\">Protip 2</font>: pandas has a [get_dummies encoder](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html).  Another [reference](https://chrisalbon.com/python/pandas_convert_categorical_to_dummies.html) is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "def hot_encoder(df, column_name):\n",
    "    \"\"\"\n",
    "    Given a dataframe and the name of a column in that\n",
    "    dataframe, one-hot encode that column and return the\n",
    "    dataframe with the encoded data instead of the original\n",
    "    column\n",
    "    \"\"\"\n",
    "    ### fill this in!\n",
    "    print(\"one-hot encoding {}\".format(column_name))\n",
    "    column = df[column_name].tolist()\n",
    "    # needs to be an N x 1 numpy array \n",
    "    column = np.reshape(column, (len(column), 1))\n",
    "    \n",
    "    enc = sklearn.preprocessing.OneHotEncoder()\n",
    "    enc.fit(column)\n",
    "    new_column = enc.transform(column).toarray()\n",
    "    \n",
    "    # making titles for the new columns, and appending them to dataframe\n",
    "    column_titles = []\n",
    "    for ii in range( len(new_column[0]) ):\n",
    "        this_column_name = column_name+\" \"+str(ii)\n",
    "        df[this_column_name] = new_column[:,ii]\n",
    "    # now that we've got the dummy columns, drop the original one\n",
    "    df.drop(column_name, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll take the ``to_transform`` list that you populated above with categorical variables, and use that to loop through columns that will be one-hot encoded.\n",
    "\n",
    "One note before you code that up: one-hot encoding comes with the baggage that it makes your dataset bigger--sometimes a lot bigger.  In the countries example above, one column that encoded the country has now been expanded out to three columns.  You can imagine that this can sometimes get really, really big (imagine a column encoding all the counties in the United States, for example).  \n",
    "\n",
    "There are some columns in this example that will really blow up the dataset, so we'll remove them before proceeding with the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amount_tsh' 'funder' 'gps_height' 'installer' 'longitude' 'latitude'\n",
      " 'wpt_name' 'num_private' 'basin' 'subvillage' 'region' 'region_code'\n",
      " 'district_code' 'lga' 'ward' 'population' 'public_meeting' 'recorded_by'\n",
      " 'scheme_management' 'scheme_name' 'permit' 'construction_year'\n",
      " 'extraction_type' 'extraction_type_group' 'extraction_type_class'\n",
      " 'management' 'management_group' 'payment' 'payment_type' 'water_quality'\n",
      " 'quality_group' 'quantity' 'quantity_group' 'source' 'source_type'\n",
      " 'source_class' 'waterpoint_type' 'waterpoint_type_group']\n",
      "one-hot encoding region\n",
      "one-hot encoding lga\n",
      "one-hot encoding public_meeting\n",
      "one-hot encoding recorded_by\n",
      "one-hot encoding scheme_management\n",
      "one-hot encoding permit\n",
      "one-hot encoding extraction_type\n",
      "one-hot encoding extraction_type_group\n",
      "one-hot encoding extraction_type_class\n",
      "one-hot encoding management\n",
      "one-hot encoding management_group\n",
      "one-hot encoding payment\n",
      "one-hot encoding payment_type\n",
      "one-hot encoding water_quality\n",
      "one-hot encoding quality_group\n",
      "one-hot encoding quantity\n",
      "one-hot encoding quantity_group\n",
      "one-hot encoding source\n",
      "one-hot encoding source_type\n",
      "one-hot encoding source_class\n",
      "one-hot encoding waterpoint_type\n",
      "one-hot encoding waterpoint_type_group\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>region 0</th>\n",
       "      <th>...</th>\n",
       "      <th>waterpoint_type 3</th>\n",
       "      <th>waterpoint_type 4</th>\n",
       "      <th>waterpoint_type 5</th>\n",
       "      <th>waterpoint_type 6</th>\n",
       "      <th>waterpoint_type_group 0</th>\n",
       "      <th>waterpoint_type_group 1</th>\n",
       "      <th>waterpoint_type_group 2</th>\n",
       "      <th>waterpoint_type_group 3</th>\n",
       "      <th>waterpoint_type_group 4</th>\n",
       "      <th>waterpoint_type_group 5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69572</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1399</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34310</th>\n",
       "      <td>25.0</td>\n",
       "      <td>686</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67743</th>\n",
       "      <td>0.0</td>\n",
       "      <td>263</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>1986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount_tsh  gps_height  longitude   latitude  num_private  region_code  \\\n",
       "id                                                                              \n",
       "69572      6000.0        1390  34.938093  -9.856322            0           11   \n",
       "8776          0.0        1399  34.698766  -2.147466            0           20   \n",
       "34310        25.0         686  37.460664  -3.821329            0           21   \n",
       "67743         0.0         263  38.486161 -11.155298            0           90   \n",
       "19728         0.0           0  31.130847  -1.825359            0           18   \n",
       "\n",
       "       district_code  population  construction_year  region 0  \\\n",
       "id                                                              \n",
       "69572              5         109               1999       0.0   \n",
       "8776               2         280               2010       0.0   \n",
       "34310              4         250               2009       0.0   \n",
       "67743             63          58               1986       0.0   \n",
       "19728              1           0                  0       0.0   \n",
       "\n",
       "                ...             waterpoint_type 3  waterpoint_type 4  \\\n",
       "id              ...                                                    \n",
       "69572           ...                           0.0                0.0   \n",
       "8776            ...                           0.0                0.0   \n",
       "34310           ...                           0.0                1.0   \n",
       "67743           ...                           0.0                1.0   \n",
       "19728           ...                           0.0                0.0   \n",
       "\n",
       "       waterpoint_type 5  waterpoint_type 6  waterpoint_type_group 0  \\\n",
       "id                                                                     \n",
       "69572                1.0                0.0                      0.0   \n",
       "8776                 1.0                0.0                      0.0   \n",
       "34310                0.0                0.0                      0.0   \n",
       "67743                0.0                0.0                      0.0   \n",
       "19728                1.0                0.0                      0.0   \n",
       "\n",
       "       waterpoint_type_group 1  waterpoint_type_group 2  \\\n",
       "id                                                        \n",
       "69572                      0.0                      0.0   \n",
       "8776                       0.0                      0.0   \n",
       "34310                      0.0                      0.0   \n",
       "67743                      0.0                      0.0   \n",
       "19728                      0.0                      0.0   \n",
       "\n",
       "       waterpoint_type_group 3  waterpoint_type_group 4  \\\n",
       "id                                                        \n",
       "69572                      0.0                      1.0   \n",
       "8776                       0.0                      1.0   \n",
       "34310                      0.0                      1.0   \n",
       "67743                      0.0                      1.0   \n",
       "19728                      0.0                      1.0   \n",
       "\n",
       "       waterpoint_type_group 5  \n",
       "id                              \n",
       "69572                      0.0  \n",
       "8776                       0.0  \n",
       "34310                      0.0  \n",
       "67743                      0.0  \n",
       "19728                      0.0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(features_df.columns.values)\n",
    "\n",
    "#GETTING RID OF COLs WE DON'T NEED\n",
    "# all these \"if\" statements protect us from errors\n",
    "# if/when we run this code more than once\n",
    "if \"funder\" in features_df.columns.values:\n",
    "    features_df.drop(\"funder\", axis=1, inplace=True)\n",
    "    columns_to_transform.remove(\"funder\")\n",
    "if \"installer\" in features_df.columns.values:   \n",
    "    features_df.drop(\"installer\", axis=1, inplace=True)\n",
    "    columns_to_transform.remove(\"installer\")        \n",
    "if \"wpt_name\" in features_df.columns.values:\n",
    "    features_df.drop(\"wpt_name\", axis=1, inplace=True)\n",
    "    columns_to_transform.remove(\"wpt_name\")\n",
    "if \"subvillage\" in features_df.columns.values:\n",
    "    features_df.drop(\"subvillage\", axis=1, inplace=True)\n",
    "    columns_to_transform.remove(\"subvillage\")\n",
    "if \"ward\" in features_df.columns.values:\n",
    "    features_df.drop(\"ward\", axis=1, inplace=True)\n",
    "    columns_to_transform.remove(\"ward\")\n",
    "if \"basin\" in features_df.columns.values:\n",
    "    features_df.drop(\"basin\", axis=1, inplace=True)\n",
    "    columns_to_transform.remove(\"basin\")\n",
    "if \"scheme_name\" in features_df.columns.values:\n",
    "    features_df.drop(\"scheme_name\", axis=1, inplace=True)\n",
    "    columns_to_transform.remove(\"scheme_name\")\n",
    "\n",
    "for feature in columns_to_transform:\n",
    "    features_df = hot_encoder(features_df, feature)\n",
    "    \n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the features are a little fixed up, I'd invite you to rerun the models, and see if the cross_val_score goes up as a result.  It is also a great chance to take some of the theory discussion from the workshop and play around with the parameters of your models, and see if you can increase their scores that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7820202   0.78439394  0.78151515]\n"
     ]
    }
   ],
   "source": [
    "X = features_df.as_matrix()\n",
    "y = labels_df[\"status_group\"].tolist()\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score(clf, X, y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end workflows using Pipeline and GridSearchCV\n",
    "\n",
    "So far we have made a nice workflow using a few ideas assembled in a script-like workflow.  A few spots remain where we can tighten things up though:\n",
    "\n",
    "* the best model, the random forest, has a lot of parameters that we'd have to work through if we really wanted to tune it\n",
    "* after dummying, we have _lots_ of features, probably only a subset of which are really offering any discriminatory power (this is a version of the bias-variance tradeoff)\n",
    "* maybe there's a way to make the code more streamlined (hint: there is)\n",
    "\n",
    "We will solve all these with two related and lovely tools in sklearn: Pipeline and GridSearchCV.\n",
    "\n",
    "Pipeline in sklearn is a tool for chaining together multiple pieces of a workflow into a single coherent analysis.  In our example, we will chain together a tool for feature selection, to will address the second point, which then feeds our optimized feature set into the random forest model, all in a few lines of code (which addresses the third point).\n",
    "\n",
    "To get to the first point, about finding the best parameters--that's where the magic of GridSearchCV comes in.  But first we need to get the feature selector and pipeline up and running, so let's do that now.\n",
    "\n",
    "In ``sklearn.feature_selection`` there is a useful tool, ``SelectKBest`` [(link)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) that you should use.  By default, this will select the 10 best features; that seems like it might be too few features to do well on this problem, so change the number of features to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# create a SelectKBest transformer and fit/transform the dataset\n",
    "import sklearn.feature_selection\n",
    "\n",
    "select = sklearn.feature_selection.SelectKBest(k=100)\n",
    "selected_X = select.fit_transform(X, y)\n",
    "\n",
    "print(selected_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "After selecting the 100 best features, the natural next step would be to run our random forest again to see if it does a little better with fewer features.  So we would have ``SelectKBest`` doing selection, with the output of that process going straight into a classifier.  A [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) packages the transformation step of ``SelectKBest`` with the estimation step of ``RandomForestClassifier`` into a coherent workflow.\n",
    "\n",
    "Why might you want to use ``Pipeline`` instead of keeping the steps separate?\n",
    "\n",
    "  * makes code more readable\n",
    "  * don't have to worry about keeping track data during intermediate steps, for example between transforming and estimating\n",
    "  * makes it trivial to move ordering of the pipeline pieces, or to swap pieces in and out\n",
    "  * *Allows you to do GridSearchCV on your workflow*\n",
    "\n",
    "This last point is, in my opinion, the most important.  We will get to it very soon, but first let's get a pipeline up and running that does ``SelectKBest`` followed by ``RandomForestClassifier``.\n",
    "\n",
    "In the code box below, I've also set up a slightly better training/testing structure, where I am explicitly splitting the data into training and testing sets which we'll use below.  The  training/testing split before was handled automatically in ``cross_val_score,`` but we'll be using a different evaluation metric from here forward, the classification report, which requires us to handle the train/test split ourselves.\n",
    "\n",
    "Note: when you do ``SelectKBest``, you might see a warning about a bunch of features that are constant.  This isn't a problem (necessarily).  It's giving you a heads up that the indicated features don't show any variation, which could be a signal that something is wrong or that ``SelectKBest`` might be doing something unexpected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.78      0.78      7458\n",
      "          1       0.44      0.37      0.40      1425\n",
      "          2       0.81      0.83      0.82     10719\n",
      "\n",
      "avg / total       0.77      0.78      0.78     19602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.pipeline\n",
    "\n",
    "select = sklearn.feature_selection.SelectKBest(k=100)\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "steps = [('feature_selection', select),\n",
    "         ('random_forest', clf)]\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# fit your pipeline on X_train and y_train\n",
    "pipeline.fit( X_train, y_train )\n",
    "# call pipeline.predict() on your X_test data to make a set of test predictions\n",
    "y_prediction = pipeline.predict( X_test )\n",
    "# test your predictions using sklearn.classification_report()\n",
    "report = sklearn.metrics.classification_report( y_test, y_prediction )\n",
    "# and print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the classification report\n",
    "\n",
    "A brief aside--we've switched from ``cross_val_score`` to ``classification_report`` for evaluation, mostly to show you two different ways to evaluating a model.  The classification report has the advantage of giving you a lot more information, and if (for example) one class is more important to get right than the others (say you're trying to zero in on non-functional wells, so finding those correctly is more important than getting the functional wells right).\n",
    "\n",
    "For more information, the [sklearn docs](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) on ``classification_report`` are, like all the sklearn docs, incredibly helpful.  For interpreting the various metrics, [this page](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html) may also help.\n",
    "\n",
    "### GridSearchCV\n",
    "We're in the home stretch now. When we decided to select the 100 best features, setting that number to 100 was kind of a hand-wavey decision. Similarly, the RandomForestClassifier that we're using right now has all its parameters set to their default values, which might not be optimal.\n",
    "\n",
    "So, a straightforward thing to do now is to try different values of ``k`` and any ``RandomForestClassifier`` parameters we want to tune (for the sake of concreteness, let's play with n_estimators and min_samples_split). Trying lots of values for each of these free parameters is tedious, and there can sometimes be interactions between the choices you make in one step and the optimal value for a downstream step. In other words, to avoid local optima, you should try all the combinations of parameters, and not just vary them independently. So if you want to try 5 different values each for ``k``, ``n_estimators`` and ``min_samples_split``, that means 5 x 5 x 5 = 125 different combinations to try. Not something you want to do by hand.\n",
    "\n",
    "``GridSearchCV`` allows you to construct a grid of all the combinations of parameters, tries each combination, and then reports back the best combination/model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158 164] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [128 158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 20.8min finished\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [158] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JP\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.78      0.80      7458\n",
      "          1       0.50      0.34      0.41      1425\n",
      "          2       0.81      0.87      0.84     10719\n",
      "\n",
      "avg / total       0.79      0.79      0.79     19602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.grid_search\n",
    "\n",
    "# create a GridSearchCV estimator that looks at different values for k in SelectKBest,\n",
    "# as well as different n_estimators values for the random forest\n",
    "\n",
    "# then fit/predict with your GridSearchCV object, and print out a classification_report\n",
    "parameters = dict(feature_selection__k=[100, 200], \n",
    "              random_forest__n_estimators=[50, 200],\n",
    "              random_forest__min_samples_split=[2, 3, 4])\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline, param_grid=parameters, verbose=True)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "y_predictions = cv.predict(X_test)\n",
    "report = sklearn.metrics.classification_report(y_test, y_predictions)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
